{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.linalg import eigh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementering kernels and do tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rbf_kernel(X, sigma, diag=1):\n",
    "    \"\"\"\"Basic SVM with predefined kernel matrix\"\"\"\n",
    "    \n",
    "    N = X.shape[0]\n",
    "    K = np.zeros((N,N))\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i == j:\n",
    "                K[i,j] = diag\n",
    "            else:\n",
    "                x_i = X[i, :].reshape(1,-1)\n",
    "                x_j = X[j, :].reshape(1,-1)\n",
    "\n",
    "                K[i, j] = np.exp(-cdist(x_i, x_j, 'sqeuclidean') / (sigma ** 2)) # euclidean?\n",
    "    return K\n",
    "\n",
    "\n",
    "def make_D_matrix(K):\n",
    "    K_sum = np.sum(K, axis=1)\n",
    "    D = np.diag(K_sum)\n",
    "    return D\n",
    "\n",
    "\n",
    "def make_L_matrix(K, D):\n",
    "    D_temp = np.diag( np.diag(D) ** -0.5 )\n",
    "    L = D_temp @ K @ D_temp\n",
    "    return L\n",
    "\n",
    "\n",
    "def step_transfer(L, k=2):\n",
    "    w, v = eigh(L)\n",
    "    lambda_cut = w[-k]\n",
    "    \n",
    "    w = np.where(w >= lambda_cut, 1, 0)\n",
    "    L_hat = np.dot(v, np.dot(np.diag(w), v.T))\n",
    "    D_hat = np.diag(1/np.diag(L_hat))\n",
    "    K_hat = D_hat**(1/2) @ L_hat @ D_hat**(1/2)\n",
    "    \n",
    "    return L_hat, D_hat, K_hat\n",
    "\n",
    "\n",
    "def linear_step_transfer(L, k=2):\n",
    "    w, v = eigh(L)\n",
    "    lambda_cut = w[-k]\n",
    "    w = np.where(w >= lambda_cut, w, 0)\n",
    "    \n",
    "    L_hat = np.dot(v, np.dot(np.diag(w), v.T))\n",
    "    D_hat = np.diag(1/np.diag(L_hat))\n",
    "    K_hat = D_hat**(1/2) @ L_hat @ D_hat**(1/2)\n",
    "\n",
    "    return L_hat, D_hat, K_hat\n",
    "\n",
    "\n",
    "def polynomial_transfer(L, D, K, t):\n",
    "    L_hat = L ** t\n",
    "    D_hat = np.diag(1/np.diag(L_hat))\n",
    "    K_hat = D_hat**(1/2) @ D**(1/2) @ (LA.inv(D) @ K)**t @ D**(1/2) @ D_hat**(1/2)\n",
    "    K_hat = preprocessing.scale(K_hat)\n",
    "\n",
    "    return L_hat, D_hat, K_hat\n",
    "\n",
    "\n",
    "def apply_transfer_func(L, D, K, hyperparams, type=\"linear\"):\n",
    "    \"\"\"hyperparams: k for step and linear_step, t for polynomial\"\"\"\n",
    "    if type == \"linear\":\n",
    "        return L, D, K\n",
    "    if type == \"step\":\n",
    "        k = hyperparams['k']\n",
    "        return step_transfer(L, k)\n",
    "    if type == \"linear_step\":\n",
    "        k = hyperparams['k']\n",
    "        return linear_step_transfer(L)\n",
    "    if type == \"polynomial\":\n",
    "        t = hyperparams['t']\n",
    "        return polynomial_transfer(L, D, K, t)\n",
    "        \n",
    "    raise ValueError(\"wrong argument\")\n",
    "\n",
    "    \n",
    "def accuracy(t, y):\n",
    "    val = 0.0\n",
    "    N = len(t)\n",
    "    for i in range(N):\n",
    "        if t[i] == y[i]:\n",
    "            val += 1\n",
    "    \n",
    "    return val / N\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "def test_svm(X, Y, tf_fun, C=1, sigma=1, **kwargs):\n",
    "    \"\"\"Test SVM one time\"\"\"\n",
    "    \n",
    "    # Shuffle data\n",
    "    np.random.seed(40)\n",
    "    n_sample = len(X)\n",
    "    order = np.random.permutation(n_sample)\n",
    "    X = X[order]\n",
    "    Y = Y[order].astype(np.float)\n",
    "    \n",
    "    # Make Kernel\n",
    "    K = rbf_kernel(X, sigma)\n",
    "    D = make_D_matrix(K)\n",
    "    L = make_L_matrix(K, D)\n",
    "    \n",
    "    L, D, K = apply_transfer_func(L, D, K, kwargs, tf_fun)\n",
    "    \n",
    "    # Remove data without labels\n",
    "    K_train = K[:70,:70]\n",
    "    Y_train = Y[:70]\n",
    "    \n",
    "    K_test = K[70:100,:70]\n",
    "    \n",
    "    # Apply to SVM\n",
    "    clf = SVC(kernel=\"precomputed\", C=C)\n",
    "    clf.fit(K_train, Y_train)\n",
    "    \n",
    "    y_pred = clf.predict(K_test)\n",
    "    print(\"accuracy:\", accuracy(y_pred, Y[70:100]))\n",
    "\n",
    "    \n",
    "def run_test_svm():\n",
    "    iris = load_iris()\n",
    "    X = iris.data[:,:2]\n",
    "    y = iris.target\n",
    "\n",
    "    X = X[y != 0]\n",
    "    y = y[y != 0]\n",
    "    \n",
    "    test_svm(X, y, \"linear_step\", k=2)\n",
    "\n",
    "    \n",
    "run_test_svm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    iris = load_iris()\n",
    "    X = iris.data[:,:2]\n",
    "    y = iris.target\n",
    "\n",
    "    X = X[y != 0]\n",
    "    y = y[y != 0]\n",
    "    \n",
    "    n_sample = len(X)\n",
    "    order = np.random.permutation(n_sample)\n",
    "    X = X[order]\n",
    "    y = y[order].astype(np.float)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def k_fold_svm_error(X_train, y_train, C, sigma, tf_fun=\"linear\"):\n",
    "    \"\"\"Compute error mean and std using k-fold cross validation with k=10 using SVM with specified kernel type\"\"\"\n",
    "    errors = []\n",
    "\n",
    "    # used for indexing in loop\n",
    "    fold_size = int(X_train.shape[0] / 10)\n",
    "\n",
    "    for fold_n in range(10):\n",
    "        # splits training data into 3 separate arrays\n",
    "        x_splits = np.vsplit(X_train, [fold_n * fold_size, fold_n * fold_size + fold_size])\n",
    "\n",
    "        # middle set is current validation set\n",
    "        x_validation_set = x_splits[1]\n",
    "        # merge first and second array from split to get training set\n",
    "        x_training_set = np.vstack((x_splits[0], x_splits[2]))\n",
    "\n",
    "        # do same thing for y labels\n",
    "        y_splits = np.split(y_train, [fold_n * fold_size, fold_n * fold_size + fold_size])\n",
    "        y_validation_set = y_splits[1]\n",
    "        y_training_set = np.append(y_splits[0], y_splits[2])\n",
    "\n",
    "        # get error for current fold\n",
    "        errors.append(\n",
    "            get_svm_error(\n",
    "                x_training_set,\n",
    "                x_validation_set,\n",
    "                y_training_set,\n",
    "                y_validation_set,\n",
    "                C,\n",
    "                sigma,\n",
    "                tf_fun,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    errors = np.array(errors)   \n",
    "    return errors.mean(), errors.std()\n",
    "\n",
    "\n",
    "def get_svm_error(x_training_set, x_validation_set, y_training_set, y_validation_set, C, sigma, type=\"linear\"):    \n",
    "    N_train = x_training_set.shape[0]\n",
    "    X_t = np.concatenate([x_training_set, x_validation_set])\n",
    "\n",
    "    K = rbf_kernel(X_t, sigma)\n",
    "    D = make_D_matrix(K)\n",
    "    L = make_L_matrix(K, D)\n",
    "    \n",
    "    L, D, K = apply_transfer_func(L, D, K, {}, type)\n",
    "    \n",
    "    K_train = K[:N_train, :N_train]\n",
    "    K_val = K[N_train:, :N_train]\n",
    "    \n",
    "    clf = SVC(kernel=\"precomputed\", C=C)\n",
    "    clf.fit(K_train, y_training_set)\n",
    "    \n",
    "    y_pred = clf.predict(K_val)\n",
    "    \n",
    "    err = 1 - accuracy(y_pred, y_validation_set)\n",
    "    return err\n",
    "\n",
    "def find_hyperparameters(X_train, y_train, c_range, sigma_range):    \n",
    "    lowest_error = 1.0\n",
    "    best_parameter_values = [0, 0]\n",
    "    \n",
    "    iters = len(c_range) * len(sigma_values)\n",
    "    i = 0\n",
    "\n",
    "    for c in c_values:\n",
    "        for sigma in sigma_values:\n",
    "            current_error,_ = k_fold_svm_error(X_train, y_train, c, sigma)\n",
    "\n",
    "            # print(\"c: {}\\t sigma: {}\\t error: {}\".format(c, sigma, current_error))\n",
    "            if (current_error < lowest_error):\n",
    "                lowest_error = current_error\n",
    "                best_parameter_values = c, sigma\n",
    "            \n",
    "            if i % 4 == 0:\n",
    "                print(\"{} / {}\".format(i, iters))\n",
    "            i += 1\n",
    "    \n",
    "    return best_parameter_values[0], best_parameter_values[1], lowest_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 36\n",
      "4 / 36\n",
      "8 / 36\n",
      "12 / 36\n",
      "16 / 36\n",
      "20 / 36\n",
      "24 / 36\n",
      "28 / 36\n",
      "32 / 36\n",
      "c: 0.1\t sigma: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# split data for finding hyperparams and for computing model error\n",
    "np.random.seed(40)\n",
    "# load data\n",
    "X, y = load_data()\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# find optimal hyperparams\n",
    "c_values = [0.01, 0.1, 1, 10, 100, 1000]\n",
    "sigma_values = [0.01, 0.1, 1, 10, 100, 1000]\n",
    "c, sigma, _ = find_hyperparameters(X, y, c_values, sigma_values)\n",
    "print(\"c: {}\\t sigma: {}\".format(c, sigma))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "Here under we can start to run experiment with the hyperparams we found above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 100\n",
      "20 / 100\n",
      "40 / 100\n",
      "60 / 100\n",
      "80 / 100\n",
      "\n",
      "    model: polynomial\n",
      "    data: iris (all features)\n",
      "    datapoints: 100\n",
      "    datapoints (label/unlabel/val): 40 40 20\n",
      "    perc_label: 0.4\n",
      "    kwargs: {'k': 2, 't': 3}\n",
      "    sigma: 1\n",
      "    c: 1\n",
      "    error: 0.0735 (0.04973)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def run_iris_experiment_2():\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def run_iris_experiment():\n",
    "    sigma = 1\n",
    "    c = 1\n",
    "    tf_fun = \"polynomial\"\n",
    "    kwargs = {}\n",
    "    kwargs[\"k\"] = 2\n",
    "    kwargs[\"t\"] = 3\n",
    "    perc_val = 0.2\n",
    "    perc_label = 0.4\n",
    "    perc_unlabel = 1 - perc_label - perc_val\n",
    "    assert(perc_val + perc_label + perc_unlabel == 1)\n",
    "    \n",
    "    # kwargs[\"k\"] for step and linear_step\n",
    "    # kwards[\"t\"] for polynomial\n",
    "    \n",
    "    errors = []\n",
    "\n",
    "    np.random.seed(40)\n",
    "    # load data\n",
    "    iris = load_iris()\n",
    "    X = iris.data #X = iris.data[:,:2]\n",
    "    y = iris.target\n",
    "\n",
    "    X = X[y != 0]\n",
    "    y = y[y != 0]\n",
    "    \n",
    "    n_sample = -1\n",
    "    n_train = -1\n",
    "    n_unlabel = -1\n",
    "    n_val = -1\n",
    "    \n",
    "    # time for experiment\n",
    "    for test_no in range(100):\n",
    "        if test_no % 20 == 0:\n",
    "            print(\"{} / {}\".format(test_no, 100))\n",
    "            \n",
    "        # randomize\n",
    "        n_sample = len(X)\n",
    "        order = np.random.permutation(n_sample)\n",
    "        X = X[order]\n",
    "        y = y[order].astype(np.float)\n",
    "\n",
    "\n",
    "        # Calculate split\n",
    "        n_train = int(n_sample * perc_label)\n",
    "        n_unlabel = int(n_sample * perc_unlabel)\n",
    "        n_val = int(n_sample * perc_val)\n",
    "\n",
    "        idx_train_end = n_train + 1\n",
    "        idx_val_start = n_train + n_unlabel\n",
    "\n",
    "        K = rbf_kernel(X, sigma)\n",
    "        D = make_D_matrix(K)\n",
    "        L = make_L_matrix(K, D)\n",
    "\n",
    "        L, D, K = apply_transfer_func(L, D, K, kwargs, tf_fun)\n",
    "\n",
    "        K_train = K[:idx_train_end, :idx_train_end]\n",
    "        Y_train = y[:idx_train_end]\n",
    "\n",
    "        K_val = K[idx_val_start:, :idx_train_end]\n",
    "\n",
    "        clf = SVC(kernel=\"precomputed\", C=c)\n",
    "        clf.fit(K_train, Y_train)\n",
    "\n",
    "        y_pred = clf.predict(K_val)\n",
    "        acc = accuracy(y_pred, y[idx_val_start:])\n",
    "        err = 1 - acc\n",
    "\n",
    "        errors.append(err)\n",
    "    \n",
    "    errors = np.array(errors)\n",
    "\n",
    "    mean_err = errors.mean()\n",
    "    std_err = errors.std()\n",
    "    \n",
    "    results = \"\"\"\n",
    "    model: {}\n",
    "    data: {}\n",
    "    datapoints: {}\n",
    "    datapoints (label/unlabel/val): {} {} {}\n",
    "    perc_label: {}\n",
    "    kwargs: {}\n",
    "    sigma: {}\n",
    "    c: {}\n",
    "    error: {:.4} ({:.4})\n",
    "    \"\"\".format(\n",
    "        tf_fun,\n",
    "        \"iris (all features)\",\n",
    "        n_sample,\n",
    "        n_train, n_unlabel, n_val,\n",
    "        perc_label,\n",
    "        kwargs,\n",
    "        sigma,\n",
    "        c,\n",
    "        mean_err, std_err\n",
    "    )\n",
    "    print(results)\n",
    "    \n",
    "run_iris_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow_data(train_size, unlabel_size, test_size):   \n",
    "    x_train_bow = np.load('Embeddings/x_train_bow.npy').item().toarray()\n",
    "    x_test_bow = np.load('Embeddings/x_test_bow.npy').item().toarray()\n",
    "\n",
    "    #x_train_bow = np.load('Embeddings/x_train_trans_FT.npy')\n",
    "    #x_test_bow = np.load('Embeddings/x_test_trans_FT.npy')\n",
    "    \n",
    "    y_train_text = np.load('Embeddings/y_train.npy')\n",
    "    y_test_text = np.load('Embeddings/y_test.npy')\n",
    "    \n",
    "    y_train = np.zeros(y_train_text.shape)\n",
    "    \n",
    "    y_train[y_train_text == \"positive\"] = 0\n",
    "    y_train[y_train_text == \"negative\"] = 1\n",
    "    y_train[y_train_text == \"neutral\"] = 2\n",
    "    \n",
    "    y_test = np.zeros(y_test_text.shape)\n",
    "        \n",
    "    y_test[y_test_text == \"positive\"] = 0\n",
    "    y_test[y_test_text == \"negative\"] = 1\n",
    "    y_test[y_test_text == \"neutral\"] = 2\n",
    "    \n",
    "    X_test = x_test_bow[y_test != 2]\n",
    "    y_test = y_test[y_test != 2]\n",
    "    \n",
    "    X = x_train_bow[y_train != 2]\n",
    "    y = y_train[y_train != 2]\n",
    "    \n",
    "    # X positive = 1891\n",
    "    # X negative = 7342\n",
    "    \n",
    "    n_sample = len(X)\n",
    "    order = np.random.permutation(n_sample)\n",
    "    X = X[order]\n",
    "    y = y[order].astype(np.float)\n",
    "    \n",
    "    order = np.random.permutation(len(X_test))\n",
    "    X_test = X_test[order]\n",
    "    y_test = y_test[order].astype(np.float)\n",
    "    \n",
    "    \n",
    "    X_train_pos_red = X[y == 0][:train_size // 2]\n",
    "    y_train_pos_red = y[y == 0][:train_size // 2]\n",
    "    X_train_neg_red = X[y == 1][:train_size // 2]\n",
    "    y_train_neg_red = y[y == 1][:train_size // 2]\n",
    "    \n",
    "    X_test_red = X_test[:test_size] \n",
    "    y_test_red = y_test[:test_size]\n",
    "    \n",
    "    X_unlabel_pos = X[y == 0][train_size // 2: unlabel_size // 2 + train_size // 2]\n",
    "    y_unlabel_pos = y[y == 0][train_size // 2: unlabel_size // 2 + train_size // 2]\n",
    "    X_unlabel_neg = X[y == 1][train_size // 2: unlabel_size // 2 + train_size // 2]\n",
    "    y_unlabel_pos = y[y == 1][train_size // 2: unlabel_size // 2 + train_size // 2]\n",
    "    \n",
    "\n",
    "    X_red = np.concatenate([X_train_pos_red, X_train_neg_red, X_unlabel_pos, X_unlabel_neg, X_test_red])\n",
    "    y_red = np.concatenate([y_train_pos_red, y_train_neg_red])\n",
    "    \n",
    "    print(X_red.shape)\n",
    "    return X_red, y_red, y_test_red\n",
    "\n",
    "# ans = get_bow_data(10, 190, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 100\n",
      "(240, 12965)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X.shape[1] = 20 should be equal to 2, the number of features at training time",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-7830ce08879c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m \u001b[0mrun_BoW_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-131-7830ce08879c>\u001b[0m in \u001b[0;36mrun_BoW_experiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \"\"\"\n\u001b[0;32m--> 576\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \"\"\"\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    476\u001b[0m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[1;32m    477\u001b[0m                              \u001b[0;34m\"the number of features at training time\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m                              (n_features, self.shape_fit_[1]))\n\u001b[0m\u001b[1;32m    479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X.shape[1] = 20 should be equal to 2, the number of features at training time"
     ]
    }
   ],
   "source": [
    "def run_BoW_experiment():\n",
    "    sigma = 1\n",
    "    c = 1\n",
    "    tf_fun = \"step\"\n",
    "    kwargs = {}\n",
    "    kwargs[\"k\"] = 2\n",
    "    kwargs[\"t\"] = 2\n",
    "    perc_val = 0.2\n",
    "    perc_label = 0.1\n",
    "    perc_unlabel = 1 - perc_label - perc_val\n",
    "    assert(perc_val + perc_label + perc_unlabel == 1)\n",
    "    \n",
    "    # kwargs[\"k\"] for step and linear_step\n",
    "    # kwards[\"t\"] for polynomial\n",
    "    \n",
    "    errors = []\n",
    "\n",
    "    np.random.seed(40)\n",
    "    \n",
    "    train_size = 20\n",
    "    unlabel_size = 180\n",
    "    test_size = 40\n",
    "\n",
    "    n_sample = -1\n",
    "    n_train = -1\n",
    "    n_unlabel = -1\n",
    "    n_val = -1\n",
    "    \n",
    "    # time for experiment\n",
    "    for test_no in range(10):\n",
    "        if test_no % 20 == 0:\n",
    "            print(\"{} / {}\".format(test_no, 100))\n",
    "            \n",
    "        \n",
    "        X_red, y_red, y_test_red = get_bow_data(train_size, unlabel_size, test_size)\n",
    "        \n",
    "        K = rbf_kernel(X_red, sigma)\n",
    "        D = make_D_matrix(K)\n",
    "        L = make_L_matrix(K, D)\n",
    "\n",
    "        L, D, K = apply_transfer_func(L, D, K, kwargs, tf_fun)\n",
    "        \n",
    "        K_train = K[:train_size, :train_size]\n",
    "        K_test = K[train_size + unlabel_size:, :train_size]        \n",
    "\n",
    "        #clf = SVC(kernel=\"precomputed\", C=c)\n",
    "        #clf.fit(K_train, y_red)\n",
    "        \n",
    "        clf = SVC(gamma='auto')\n",
    "        clf.fit(X, y)\n",
    "        \n",
    "        y_pred = clf.predict(K_test)\n",
    "        \n",
    "        \n",
    "        acc = accuracy(y_pred, y_test_red)\n",
    "        err = 1 - acc\n",
    "        \n",
    "        print(err)\n",
    "        \n",
    "        errors.append(err)\n",
    "    \n",
    "    errors = np.array(errors)\n",
    "\n",
    "    mean_err = errors.mean()\n",
    "    std_err = errors.std()\n",
    "    \n",
    "    results = \"\"\"\n",
    "    model: {}\n",
    "    data: {}\n",
    "    datapoints: {}\n",
    "    datapoints (label/unlabel/val): {} {} {}\n",
    "    perc_label: {}\n",
    "    kwargs: {}\n",
    "    sigma: {}\n",
    "    c: {}\n",
    "    error: {:.4} ({:.4})\n",
    "    \"\"\".format(\n",
    "        tf_fun,\n",
    "        \"Bag of words\",\n",
    "        n_sample,\n",
    "        n_train, n_unlabel, n_val,\n",
    "        perc_label,\n",
    "        kwargs,\n",
    "        sigma,\n",
    "        c,\n",
    "        mean_err, std_err\n",
    "    )\n",
    "    print(results)\n",
    "    \n",
    "run_BoW_experiment()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
