{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.linalg import eigh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementering kernels and do tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rbf_kernel(X, sigma, diag=1):\n",
    "    \"\"\"\"Basic SVM with predefined kernel matrix\"\"\"\n",
    "    \n",
    "    N = X.shape[0]\n",
    "    K = np.zeros((N,N))\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i == j:\n",
    "                K[i,j] = diag\n",
    "            else:\n",
    "                x_i = X[i, :].reshape(1,-1)\n",
    "                x_j = X[j, :].reshape(1,-1)\n",
    "\n",
    "                K[i, j] = np.exp(-cdist(x_i, x_j, 'sqeuclidean') / (sigma ** 2)) # euclidean?\n",
    "    return K\n",
    "\n",
    "def make_D_matrix(K):\n",
    "    K_sum = np.sum(K, axis=1)\n",
    "    D = np.diag(K_sum)\n",
    "\n",
    "    return D\n",
    "\n",
    "def make_L_matrix(K, D):\n",
    "    D_temp = np.diag( np.diag(D) ** -0.5 )\n",
    "    L = D_temp @ K @ D_temp\n",
    "    \n",
    "    w, v = LA.eig(L) # w = eigenvalues, v = normalized (unit “length”) eigenvectors\n",
    "    \n",
    "    return L\n",
    "\n",
    "def step_transfer(L, k=2):\n",
    "    w, v = eigh(L)\n",
    "    lambda_cut = w[-k]\n",
    "    \n",
    "    w = np.where(w >= lambda_cut, 1, 0)\n",
    "    L_hat = np.dot(v, np.dot(np.diag(w), v.T))\n",
    "    D_hat = np.diag(1/np.diag(L_hat))\n",
    "    K_hat = D_hat**(1/2) @ L_hat @ D_hat**(1/2)\n",
    "    \n",
    "    return L_hat, D_hat, K_hat\n",
    "\n",
    "def linear_step_transfer(L, k=2):\n",
    "    w, v = eigh(L)\n",
    "    lambda_cut = w[-k]\n",
    "    w = np.where(w >= lambda_cut, w, 0)\n",
    "    \n",
    "    L_hat = np.dot(v, np.dot(np.diag(w), v.T))\n",
    "    D_hat = np.diag(1/np.diag(L_hat))\n",
    "    K_hat = D_hat**(1/2) @ L_hat @ D_hat**(1/2)\n",
    "\n",
    "    return L_hat, D_hat, K_hat\n",
    "\n",
    "def polynomial_transfer(L, D, K, t):\n",
    "    L_hat = L ** t\n",
    "    D_hat = np.diag(1/np.diag(L_hat))\n",
    "    K_hat = D_hat**(1/2) @ D**(1/2) @ (LA.inv(D) @ K)**t @ D**(1/2) @ D_hat**(1/2)\n",
    "    K_hat = preprocessing.scale(K_hat)\n",
    "\n",
    "    return L_hat, D_hat, K_hat\n",
    "\n",
    "def apply_transfer_func(L, D, K, hyperparams, type=\"linear\"):\n",
    "    \"\"\"hyperparams: k for step and linear_step, t for polynomial\"\"\"\n",
    "    if type == \"linear\":\n",
    "        return L, D, K\n",
    "    if type == \"step\":\n",
    "        k = hyperparams['k']\n",
    "        return step_transfer(L, k)\n",
    "    if type == \"linear_step\":\n",
    "        k = hyperparams['k']\n",
    "        return linear_step_transfer(L)\n",
    "    if type == \"polynomial\":\n",
    "        t = hyperparams['t']\n",
    "        return polynomial_transfer(L, D, K, t)\n",
    "        \n",
    "    raise ValueError(\"wrong argument\")\n",
    "\n",
    "def accuracy(t, y):\n",
    "    val = 0.0\n",
    "    N = len(t)\n",
    "    for i in range(N):\n",
    "        if t[i] == y[i]:\n",
    "            val += 1\n",
    "    \n",
    "    return val / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_svm(X, Y, tf_fun, C=100, sigma=1, **kwargs):\n",
    "    \"\"\"Test SVM one time\"\"\"\n",
    "    \n",
    "    # Shuffle data\n",
    "    np.random.seed(40)\n",
    "    n_sample = len(X)\n",
    "    order = np.random.permutation(n_sample)\n",
    "    X = X[order]\n",
    "    Y = Y[order].astype(np.float)\n",
    "    \n",
    "    # Make Kernel\n",
    "    K = rbf_kernel(X, sigma)\n",
    "    D = make_D_matrix(K)\n",
    "    L = make_L_matrix(K, D)\n",
    "    \n",
    "    L, D, K = apply_transfer_func(L, D, K, kwargs, tf_fun)\n",
    "    \n",
    "    # Remove data without labels\n",
    "    K_train = K[:70,:70]\n",
    "    Y_train = Y[:70]\n",
    "    \n",
    "    K_test = K[70:100,:70]\n",
    "    \n",
    "    # Apply to SVM\n",
    "    clf = SVC(kernel=\"precomputed\", C=C)\n",
    "    clf.fit(K_train, Y_train)\n",
    "    \n",
    "    y_pred = clf.predict(K_test)\n",
    "    print(\"accuracy:\", accuracy(y_pred, Y[70:100]))\n",
    "\n",
    "def run_test_svm():\n",
    "    iris = load_iris()\n",
    "    X = iris.data[:,:2]\n",
    "    y = iris.target\n",
    "\n",
    "    X = X[y != 0]\n",
    "    y = y[y != 0]\n",
    "    \n",
    "    test_svm(X, y, \"linear\")\n",
    "\n",
    "run_test_svm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_hyperparameters(X_train, y_train, C, sigma):\n",
    "    \"\"\"Validates hyperparamters using k-fold cross validation with k=10\"\"\"\n",
    "    errors = []\n",
    "\n",
    "    # used for indexing in loop\n",
    "    fold_size = int(X_train.shape[0] / 10)\n",
    "\n",
    "    for fold_n in range(10):\n",
    "        # splits training data into 3 separate arrays\n",
    "        x_splits = np.vsplit(X_train, [fold_n * fold_size, fold_n * fold_size + fold_size])\n",
    "\n",
    "        # middle set is current validation set\n",
    "        x_validation_set = x_splits[1]\n",
    "        # merge first and second array from split to get training set\n",
    "        x_training_set = np.vstack((x_splits[0], x_splits[2]))\n",
    "\n",
    "        # do same thing for y labels\n",
    "        y_splits = np.split(y_train, [fold_n * fold_size, fold_n * fold_size + fold_size])\n",
    "        y_validation_set = y_splits[1]\n",
    "        y_training_set = np.append(y_splits[0], y_splits[2])\n",
    "\n",
    "        # get error for current fold\n",
    "        errors.append(\n",
    "            get_svm_error(\n",
    "                x_training_set,\n",
    "                x_validation_set,\n",
    "                y_training_set,\n",
    "                y_validation_set,\n",
    "                C,\n",
    "                sigma,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    errors = np.array(errors)   \n",
    "    return errors.mean()\n",
    "\n",
    "\n",
    "def get_svm_error(x_training_set, x_validation_set, y_training_set, y_validation_set, C, sigma):    \n",
    "    N_train = x_training_set.shape[0]\n",
    "    X_t = np.concatenate([x_training_set, x_validation_set])\n",
    "\n",
    "    K = rbf_kernel(X_t, sigma)\n",
    "    D = make_D_matrix(K)\n",
    "    L = make_L_matrix(K, D)\n",
    "    \n",
    "    L, D, K = apply_transfer_func(L, D, K, {}, \"linear\")\n",
    "    \n",
    "    K_train = K[:N_train, :N_train]\n",
    "    K_val = K[N_train:, :N_train]\n",
    "    \n",
    "    clf = SVC(kernel=\"precomputed\", C=C)\n",
    "    clf.fit(K_train, y_training_set)\n",
    "    \n",
    "    y_pred = clf.predict(K_val)\n",
    "    \n",
    "    err = 1 - accuracy(y_pred, y_validation_set)\n",
    "    return err\n",
    "\n",
    "\n",
    "def find_hyperparameters(X_train, y_train):\n",
    "    #c_values = np.arange(0.1, 10, 0.2)\n",
    "    #sigma_values = np.arange(0.1, 2, 0.2)\n",
    "    c_values = [0.01, 0.1, 1, 10, 100, 1000]\n",
    "    sigma_values = [0.01, 0.1, 1, 10, 100, 1000]\n",
    "    \n",
    "    lowest_error = 1.0\n",
    "    best_parameter_values = [0, 0]\n",
    "    \n",
    "    iters = len(c_values) * len(sigma_values)\n",
    "    i = 0\n",
    "\n",
    "    for c in c_values:\n",
    "        for sigma in sigma_values:\n",
    "            current_error = validate_hyperparameters(X_train, y_train, c, sigma)\n",
    "\n",
    "            # print(\"c: {}\\t sigma: {}\\t error: {}\".format(c, sigma, current_error))\n",
    "            if (current_error < lowest_error):\n",
    "                lowest_error = current_error\n",
    "                best_parameter_values = c, sigma\n",
    "            \n",
    "            if i % 4 == 0:\n",
    "                print(\"{} / {}\".format(i, iters))\n",
    "            i += 1\n",
    "      \n",
    "    res = \"c: {}\\t sigma: {}\\t error: {}\".format(best_parameter_values[0], best_parameter_values[1], lowest_error)\n",
    "    return res\n",
    "\n",
    "\n",
    "def run_find_hyperparameters():\n",
    "    iris = load_iris()\n",
    "    X = iris.data[:,:2]\n",
    "    y = iris.target\n",
    "\n",
    "    X = X[y != 0]\n",
    "    y = y[y != 0]\n",
    "    \n",
    "    np.random.seed(40)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "    res = find_hyperparameters(X_train, y_train)\n",
    "    print(res)\n",
    "\n",
    "run_find_hyperparameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "Here under we can start to run experiment with the hyperparams we found above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
