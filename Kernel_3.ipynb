{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import linalg as LA\n",
    "from scipy.linalg import eigh\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# hyperparameters: Kernel, Regularization, Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kernel function\n",
    "\n",
    "def rbf_kernel(X, sigma, diag=1):\n",
    "    # Basic SVM with predefined kernel matrix\n",
    "    N = X.shape[0]\n",
    "    K = np.zeros((N,N))\n",
    "\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i == j:\n",
    "                K[i,j] = diag\n",
    "            else:\n",
    "                x_i = X[i, :].reshape(1,-1)\n",
    "                x_j = X[j, :].reshape(1,-1)\n",
    "\n",
    "                K[i, j] = np.exp(-cdist(x_i, x_j, 'sqeuclidean') / (sigma ** 2)) # euclidean?\n",
    "    return K\n",
    "\n",
    "\n",
    "def make_D_matrix(K):\n",
    "    K_sum = np.sum(K, axis=1)\n",
    "    D = np.diag(K_sum)\n",
    "\n",
    "    return D\n",
    "\n",
    "\n",
    "def make_L_matrix(K, D):\n",
    "    D_temp = np.diag( np.diag(D) ** -0.5 )\n",
    "    L = D_temp @ K @ D_temp\n",
    "    \n",
    "    w, v = LA.eig(L) # w = eigenvalues, v = normalized (unit “length”) eigenvectors\n",
    "    \n",
    "    return L\n",
    "\n",
    "def step_transfer(L, k=2):\n",
    "    w, v = eigh(L)\n",
    "    lambda_cut = w[-k]\n",
    "    \n",
    "    w = np.where(w >= lambda_cut, 1, 0)\n",
    "    L_hat = np.dot(v, np.dot(np.diag(w), v.T))\n",
    "    D_hat = np.diag(1/np.diag(L_hat))\n",
    "    K_hat = D_hat**(1/2) @ L_hat @ D_hat**(1/2)\n",
    "    \n",
    "    return L_hat, D_hat, K_hat\n",
    "\n",
    "def linear_step_transfer(L, k=2):\n",
    "    w, v = eigh(L)\n",
    "    lambda_cut = w[-k]\n",
    "    w = np.where(w >= lambda_cut, w, 0)\n",
    "    \n",
    "    L_hat = np.dot(v, np.dot(np.diag(w), v.T))\n",
    "    D_hat = np.diag(1/np.diag(L_hat))\n",
    "    K_hat = D_hat**(1/2) @ L_hat @ D_hat**(1/2)\n",
    "\n",
    "    return L_hat, D_hat, K_hat\n",
    "\n",
    "def polynomial_transfer(L, D, K, t):\n",
    "    L_hat = L ** t\n",
    "    D_hat = np.diag(1/np.diag(L_hat))\n",
    "    K_hat = D_hat**(1/2) @ D**(1/2) @ (LA.inv(D) @ K)**t @ D**(1/2) @ D_hat**(1/2)\n",
    "    K_hat = preprocessing.scale(K_hat)\n",
    "\n",
    "    return L_hat, D_hat, K_hat\n",
    "    \n",
    "\n",
    "def apply_transfer_func(L, D, K, hyperparams, type=\"linear\"):\n",
    "    if type == \"linear\":\n",
    "        return L, D, K\n",
    "    if type == \"step\":\n",
    "        k = hyperparams['k']\n",
    "        return step_transfer(L, k)\n",
    "    if type == \"linear_step\":\n",
    "        k = hyperparams['k']\n",
    "        return linear_step_transfer(L)\n",
    "    if type == \"polynomial\":\n",
    "        t = hyperparams['t']\n",
    "        return polynomial_transfer(L, D, K, t)\n",
    "        \n",
    "    raise ValueError(\"wrong argument\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def accuracy(t, y):\n",
    "    val = 0.0\n",
    "    N = len(t)\n",
    "    for i in range(N):\n",
    "        if t[i] == y[i]:\n",
    "            val += 1\n",
    "    \n",
    "    return val / N\n",
    "\n",
    "\n",
    "def test_svm(X, Y, tf_fun, C=1, sigma=1 **kwargs):\n",
    "    # Shuffle data\n",
    "    np.random.seed(40)\n",
    "    n_sample = len(X)\n",
    "    order = np.random.permutation(n_sample)\n",
    "    X = X[order]\n",
    "    Y = Y[order].astype(np.float)\n",
    "    \n",
    "    # Make Kernel\n",
    "    K = rbf_kernel(X, sigma)\n",
    "    D = make_D_matrix(K)\n",
    "    L = make_L_matrix(K, D)\n",
    "    \n",
    "    L, D, K = apply_transfer_func(L, D, K, kwargs, tf_fun)\n",
    "    \n",
    "    # Remove data without labels\n",
    "    K_red = K[:70,:70]\n",
    "    Y_red = Y[:70]\n",
    "    \n",
    "    K_test = K[70:100,:70]\n",
    "    \n",
    "    print(K_red.shape)\n",
    "    \n",
    "    # Apply to SVM\n",
    "    clf = SVC(kernel=\"precomputed\", C)\n",
    "    clf.fit(K_red, Y_red)\n",
    "    \n",
    "    # Predict and accuracy\n",
    "    y_pred = clf.predict(K_test)\n",
    "    \n",
    "    #print('t', Y[70:100])\n",
    "    #print('y', y_pred)\n",
    "    print(\"accuracy:\", accuracy(y_pred, Y[70:100]))\n",
    "    \n",
    "    \n",
    "    # Basic SVM\n",
    "    clf2 = SVC(kernel=\"linear\", C)\n",
    "    clf2.fit(X[:70], Y_red)\n",
    "    \n",
    "    y_pred2 = clf2.predict(X[70:100])\n",
    "    print(\"accuracy:\", accuracy(y_pred2, Y[70:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t =  1\n",
      "(70, 70)\n",
      "accuracy: 0.7\n",
      "accuracy: 0.6\n",
      "t =  2\n",
      "(70, 70)\n",
      "accuracy: 0.7\n",
      "accuracy: 0.6\n",
      "t =  3\n",
      "(70, 70)\n",
      "accuracy: 0.6333333333333333\n",
      "accuracy: 0.6\n",
      "t =  4\n",
      "(70, 70)\n",
      "accuracy: 0.6\n",
      "accuracy: 0.6\n",
      "t =  5\n",
      "(70, 70)\n",
      "accuracy: 0.6\n",
      "accuracy: 0.6\n",
      "t =  6\n",
      "(70, 70)\n",
      "accuracy: 0.5666666666666667\n",
      "accuracy: 0.6\n",
      "t =  7\n",
      "(70, 70)\n",
      "accuracy: 0.5\n",
      "accuracy: 0.6\n",
      "t =  8\n",
      "(70, 70)\n",
      "accuracy: 0.43333333333333335\n",
      "accuracy: 0.6\n",
      "t =  9\n",
      "(70, 70)\n",
      "accuracy: 0.43333333333333335\n",
      "accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "# load iris and split data\n",
    "iris = load_iris()\n",
    "X = iris.data[:,:2]\n",
    "y = iris.target\n",
    "\n",
    "X = X[y != 0]\n",
    "y = y[y != 0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9)\n",
    "\n",
    "T = np.arange(1, 10)\n",
    "for t in T:\n",
    "    print(\"t = \", t)\n",
    "    test_svm(X, y, \"polynomial\", t=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(399,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[6.3 2.9 6.2 3.4 6.3 3.4 6.  3.  6.3 3.3 6.3 2.8 6.4 3.2 5.6 3.  6.  2.2].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fdc4308e9330>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m \u001b[0mfind_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-fdc4308e9330>\u001b[0m in \u001b[0;36mfind_hyperparameters\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mc_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msigma_values\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mcurrent_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcurrent_error\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mlowest_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mlowest_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-fdc4308e9330>\u001b[0m in \u001b[0;36mvalidate_hyperparameters\u001b[0;34m(C, sigma)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m#get error for current fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_svm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_training_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_validation_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_training_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_validation_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-fdc4308e9330>\u001b[0m in \u001b[0;36mget_svm_error\u001b[0;34m(x_training_set, x_validation_set, y_training_set, y_validation_set, C, sigma)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0msvm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rbf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_training_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_training_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m     \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_validation_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_validation_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    144\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[1;32m    145\u001b[0m                          \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m                          accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[6.3 2.9 6.2 3.4 6.3 3.4 6.  3.  6.3 3.3 6.3 2.8 6.4 3.2 5.6 3.  6.  2.2].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#Välkommen till våran_funktion()\n",
    "'''\n",
    "# find hyperparameters c and sigma with svm\n",
    "\n",
    "best_result = 0\n",
    "best_hyperparams = [best_c, best_sigma]\n",
    "\n",
    " for c in range(C)\n",
    "    for sigma in range(Sigma)\n",
    "        # do \"runs\" svms for stable average result\n",
    "        \n",
    "        data = shuffle(data)\n",
    "        \n",
    "        res = []\n",
    "        for run in range(runs)\n",
    "             res.append(svm(data, c, sigma))\n",
    "        curr_avg_res /= runs\n",
    "        \n",
    "        if curr result is better than best_result:\n",
    "            best_result = curr_result\n",
    "            best_hyperparams = [c, sigma]        \n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "'''\n",
    "\n",
    "def find_hyperparameters():\n",
    "    #split 10% of train dataset to use as validation\n",
    "    \n",
    "    c_values=np.arange(0.0, 10,0.1 )\n",
    "    sigma_values=np.arange(0.01, 4,0.01 )\n",
    "    print(c_values.shape)\n",
    "    print(sigma_values.shape)\n",
    "    \n",
    "    lowest_error=1.0 #low is good\n",
    "    best_parameter_values=[0,0]\n",
    "    for c in c_values:\n",
    "        for sigma in sigma_values:\n",
    "            current_error=validate_hyperparameters(c,sigma)\n",
    "            if (current_error<lowest_error):\n",
    "                lowest_error=current_error\n",
    "                best_parameter_values=c, sigma\n",
    "    \n",
    "    print(best_parameter_values,lowest_error)\n",
    "def validate_hyperparameters(C, sigma):\n",
    "    \"\"\"Validates hyperparamters using k-fold cross validation with k=10\"\"\"\n",
    "    \n",
    "    #array that will contain error from each fold\n",
    "    errors=[]\n",
    "    \n",
    "    #used for indexing in loop\n",
    "    fold_size=int(X_train.shape[0]/10)\n",
    "    \n",
    "    for fold_n in range(10):\n",
    "        #splits training data into 3 separate arrays \n",
    "        x_splits = np.split(\n",
    "            X_train, [fold_n*fold_size, fold_n*fold_size+fold_size])\n",
    "        #middle set is current validation set\n",
    "        x_validation_set = x_splits[1]\n",
    "        #merge first and second array from split to get training set\n",
    "        x_training_set = np.append(x_splits[0], x_splits[2])\n",
    "\n",
    "        \n",
    "        #do same thing for y labels\n",
    "        y_splits=np.split(\n",
    "            y_train, [fold_n*fold_size, fold_n*fold_size+fold_size])\n",
    "        y_validation_set = y_splits[1]\n",
    "        y_training_set = np.append(y_splits[0], y_splits[2])\n",
    "        \n",
    "        #get error for current fold\n",
    "        errors.append(get_svm_error(x_training_set,x_validation_set,y_training_set,y_validation_set,C,sigma))\n",
    "    errors=np.array(errors)\n",
    "    return errors.mean()\n",
    "\n",
    "def get_svm_error(x_training_set,x_validation_set,y_training_set,y_validation_set,C,sigma):\n",
    "    svm=SVC(kernel=\"rbf\", C=C, gamma=sigma)\n",
    "\n",
    "    svm.fit(x_training_set,y_training_set)\n",
    "    y_pred=svm.predict(x_validation_set)\n",
    "    error=1-accuracy(y_pred,y_validation_set)\n",
    "    return error\n",
    "\n",
    "    \n",
    "\n",
    "# load iris and split data\n",
    "iris = load_iris()\n",
    "X = iris.data[:,:2]\n",
    "y = iris.target\n",
    "\n",
    "X = X[y != 0]\n",
    "y = y[y != 0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9)\n",
    "\n",
    "find_hyperparameters()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
